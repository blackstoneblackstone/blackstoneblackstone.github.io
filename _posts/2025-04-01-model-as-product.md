---
layout: post
title: "Model as Product - A New Paradigm for AI Product Evolution"
date: 2025-04-01 10:00:00 +0800
categories: blog
tags: [AI, Product, Technology Trends]
lang: en
ref: model-as-product
---

# Model as Product: A New Paradigm for AI Product Evolution

Recently, there have been two noteworthy developments in the AI community: one is GPT-4o introducing a new image generation model, and the other is Douban upgrading its "Search and Think" feature. Both examples point to an emerging concept—"Model as Product." It may sound abstract, but it could influence the future development of AI products. So what exactly does "Model as Product" mean, how does it differ from traditional AI approaches, and why is it so powerful yet not widely adopted?

## What is "Model as Product"?

Simply put, "Model as Product" treats the AI model itself as the product, with its core value coming from the model's intelligence and capabilities, rather than relying on complex software or interfaces for packaging.

For example, with GPT-4o's new image generation model, you only need to upload an image and write six characters: "Ghibli style," and it directly generates a highly accurate and adorable Ghibli animation-style image. You can even use the generated Ghibli cartoon character to create emojis or even generate a four-panel comic. You don't need to know Photoshop or switch between multiple apps—one model handles everything.

Think about the traditional image creation process: you'd need to find materials, adjust colors, draw lines, and use other tools to add text—steps so numerous they make your head spin. Now, GPT-4o's image model has "learned" all these skills and delivers the finished product directly.

This is the charm of "Model as Product"—the model can directly satisfy various scenarios without requiring you to design complex workflows or switch between different apps.

## How Does It Differ from Traditional Workflow Agents? What Are Their Respective Pros and Cons?

Traditional AI applications mostly follow a "workflow agent" model. What does this mean? It involves pre-designing fixed processes, connecting AI models with other tools, and completing tasks step by step. For example, the recently popular Manus—if you ask it to "plan a detailed itinerary for a road trip from Beijing to Shanxi," it would design a workflow similar to a TODO list:

- Search for scenic spots between Beijing and Shanxi
- Search for Beijing to Shanxi road trip guides
- Generate a detailed itinerary

The advantage of such a workflow is that it's easy to execute—following steps sequentially produces results. The disadvantage is its lack of flexibility since once the TODO list/workflow is set, it's difficult to adjust based on returned results. If search results mention recent highway construction between Beijing and Shanxi or forecasts of extreme weather, additional searches would be needed for detours and weather forecasts, ultimately requiring comprehensive itinerary adjustments.

Douban's recently tested "Search and Think" feature is another good example. Unlike traditional AI's "search first, think later" approach—where the model searches network resources based on your question, then answers with that fixed information—Douban conducts multiple rounds of searches during its thinking process. In other words, the model judges while answering: "Am I missing any information?" If so, it actively searches again, continuing this cycle until all aspects of the question are clarified.

Like the itinerary planning example earlier, "Search and Think" first searches for basic attractions and transportation options, then realizes from these results that it "needs to check the latest weather forecasts and local traffic conditions." It then conducts a second round of searches for this dynamic information, ultimately synthesizing data from various aspects—even considering transportation between attractions—to provide a comprehensive itinerary.

This is like a smart assistant adjusting strategies based on available information rather than rigidly following a predetermined route.

## Why is "Model as Product" Challenging?

If the "Model as Product" approach is so powerful, why isn't it universally adopted? Because training a model to be a universal product adaptable to different scenarios while remaining simple to use is extremely difficult:

- **High R&D barriers**: Requires powerful foundation models, quality data, and specialized reinforcement training
- **Resource-intensive**: Training models requires massive computational resources like GPU clusters, which small companies simply can't afford
- **High market risk**: Large investments and long cycles make investors prefer quick-return applications rather than these "slow and meticulous" projects
- **User experience challenges**: No matter how advanced the model, it needs a user-friendly interface. Like GPT-4o allowing image generation in the chat box, or Douban enabling automatic "Search and Think" by selecting "Deep Thinking"

## Brief Introduction: Reinforcement Learning

It's worth mentioning the core technology behind "Model as Product"—Reinforcement Learning (RL). Simply put, it allows AI to learn through trial and error, similar to training circus animals, providing rewards and feedback to gradually learn tasks.

A classic example is AlphaZero, the AI that defeated human Go champions. It didn't rely on humans teaching it moves but learned through reinforcement learning, playing against itself. Winning brought rewards, losing adjusted strategies, and after millions of games, it not only mastered Go but discovered moves humans hadn't thought of in thousands of years. This is the power of reinforcement learning—letting AI discover optimal solutions independently.

For instance, Douban's "Search and Think" was also trained through reinforcement, using simulated search databases and training sets. The model repeatedly tried different keywords and thought processes for given questions, eventually finding answers and receiving rewards. The model then attempts to understand and summarize patterns that increase the likelihood of finding similar answers in the future.

This self-learning ability is key to "Model as Product" replacing complex workflows.

## Future Outlook

Despite the challenges, "Model as Product" has become a major trend in AI development. Looking ahead, we can expect more surprises from this approach. Perhaps soon, your interaction with AI will not be limited to Q&A but will be more like collaborating with a digital partner capable of executing complex operations for you. Many of our application scenarios may be redefined: tasks that previously required switching between humans and tools can now be handled by a single AI model. From creative inspiration to organizing complex materials to decision-making solutions, AI models will provide end-to-end support directly.

Truly intelligent AI doesn't need you to tell it how to do something—it knows what to do itself. 