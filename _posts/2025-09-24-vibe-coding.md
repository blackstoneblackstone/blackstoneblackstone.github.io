---
layout: post
title: "为什么 Vibe Coding 在设计稿的还原度上那么差？"
author: 黑石
categories: [ 文章 ]
image: https://pic.iu101.org/cdn-cgi/image/width=800,quality=85,format=webp/vibe-coding-logo.png
excerpt: 分析 Vibe Coding 在设计稿还原度方面存在的问题，探讨 AI 代码生成工具在设计到代码转换过程中的技术挑战。
---

## 为什么 Vibe Coding 在设计稿还原度那么差？

![Vibe coding](https://pic.iu101.org/cdn-cgi/image/width=1200,quality=90,format=webp/d98691d8.png)


从技术原理上来说，这涉及到几个层面的根本差异：

### 1. JSON 是结构化数据，UI 视觉是空间 + 时序 + 感知的综合表达

AI 读取 JSON 本质上是模式匹配，字段、类型、结构相对固定，逻辑可枚举。

但 UI 中的"阴影效果""动态交互"是非结构化视觉语言——阴影不只是 `box-shadow: x y blur color;`，还包含光源逻辑、材质感、视觉层次意图。

AI 没有真实的"视觉感知系统"，它只是在学习像素或样式标记的统计规律，难以逆向还原出设计意图。

### 2. 动态效果 = 时间轴 + 物理模拟 + 交互上下文

你提到的 hover 效果之所以难生成，是因为它不仅是"状态 A → 状态 B"，还包含：

- **过渡曲线**（easing function）
- **交互边界**（比如鼠标进入/离开的触发逻辑）
- **视觉反馈的连续性**（如涟漪扩散的起点、方向）

这些在代码中虽然能用 CSS/JS 描述，但对 AI 而言，自然语言提示词很难精确对应到时间线与物理模型参数。目前的多模态模型本质上还是"静态画面理解"，对动态序列缺乏显式建模。

### 3. "还原度高"局限于组件级别，系统级视觉一致性需要设计思维

我们做过实验：让 AI 生成一个按钮，准确率可达 90%；但生成一组按钮+卡片+导航栏，并保持间距、色调、投影风格一致，准确率骤降至 30% 以下。

原因在于：AI 缺乏全局设计系统意识。它不会自动推演"如果主按钮阴影是 8px/透明度20%，那么卡片阴影应该是多少？"这类关联规则。

### 4. 技术瓶颈本质：视觉生成是"涌现"，UI 还原是"约束求解"

当前 AI 擅长基于大规模数据涌现新内容，但 UI 还原是强约束问题——每一个像素都可能被设计规范约束。

这更像是一个逆问题（inverse problem）：从有限的语言描述反推精确参数，本就病态且多解。人类设计师靠的是视觉经验与设计系统知识，而 AI 目前还缺乏这类可推理的视觉常识库。